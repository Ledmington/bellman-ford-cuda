\documentclass[a4paper]{article}

\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage[
backend=biber,
style=alphabetic,
sorting=ynt
]{biblatex}
\usepackage[linesnumbered, ruled, titlenotnumbered]{algorithm2e}

\addbibresource{tesi.bib}

\renewcommand{\arraystretch}{1.2}

\begin{document}
	
	\newgeometry{margin=0.8in}
	\begin{titlepage}
		\begin{center}
			
			\large
			\textbf{ALMA MATER STUDIORUM -- UNIVERSITÀ DI BOLOGNA \\ CAMPUS DI CESENA}
			\\
			\noindent\hrulefill
			\vspace{0.4cm}
			
			\Large
			Scuola di Ingegneria e Architettura \\
			Corso di Laurea Triennale in Ingegneria e Scienze Informatiche
			
			\Huge
			\vspace{4cm}
			\textbf{
				Implementazione CUDA
				\\
				dell'algoritmo di Bellman-Ford
			}
			
			\large
			\vspace{1cm}
			Tesi di laurea in 
			\\
			\textsc{High-Performance Computing}
			
			\vspace{5.5cm}
			\begin{minipage}[t]{0.64\textwidth}
				\begin{flushleft}
					\textit{Relatore} 
					\\ 
					\textbf{Prof.} \textbf{Moreno Marzolla}
				\end{flushleft}
			\end{minipage}
			\begin{minipage}[t]{0.34\textwidth}
				\begin{flushright}
					\textit{Candidato} 
					\\ 
					\textbf{Filippo Barbari}
				\end{flushright}
			\end{minipage}\\
			
			\vfill
			\noindent\hrulefill
			\vspace{0.3cm}
			\Large
			
			Seconda Sessione di Laurea
			\\
			Anno Accademico 2020-2021
		\end{center}
	\end{titlepage}
	\restoregeometry
	\newpage
	
	\tableofcontents
	\newpage
	
	\listoffigures
	\newpage
	
	\listoftables
	\newpage
	
	\listofalgorithms
	\newpage
	
	\section{Introduzione}
	L'obiettivo di questa tesi consiste nell'implementazione in linguaggio CUDA dell'algoritmo di Bellman-Ford per il Single-Source Shortest Path problem.
	
	Il capitolo \ref{section:storia} è un'introduzione al calcolo parallelo: alcuni cenni storici, l'evoluzione dell'hardware fino ai giorni nostri e le strade verso cui potrebbe dirigersi. Nel capitolo \ref{section:analisi} si analizza il problema del Single-Source Shortest Path e poi l'algoritmo proposto da Bellman e Ford. Nella stessa sezione, inoltre, si mostra la sua correttezza e i suoi pregi e difetti. Nella sezione \ref{section:design}, partendo dall'analisi del capitolo precedente, si enumerano (?) un insieme di possibili parallelizzazioni dell'algoritmo spiegando quale potrebbe essere la migliore e perchè. Nel capitolo \ref{section:impl} si discuterà dei dettagli implementativi non trascurabili che saranno presenti nel repository. Infine, nel capitolo \ref{section:perf} si mostreranno i risultati delle misure più comuni che è possibile misurare su GPU (speedup rispetto alla versione seriale e throughput) e si discuteranno.
	
	\section{Calcolo parallelo}
	\label{section:storia}
	Qui si parla della storia del calcolo parallelo, perchè è necessario, perchè si sta sviluppando così tanto e perchè le GPU sono diventate cosi importanti.
	
	\subsection{GPU e CUDA}
	Qui si parla di cos'è CUDA e come funziona. Si parla anche della struttura della memoria di una GPU CUDA e di come funziona lo scheduling.
	
	\section{Teoria}
	Qua si parla della teoria dei grafi.
	\subsection{Notazione}
	Serve?
	\subsection{Grafi e grafi planari}
	Che cos'è un grafo, da cosa è composto e che cos'è un grafo planare.
	\subsection{Cammini minimi e problema SSSP}
	Che cos'è un cammino minimo, la proprietà della disuguaglianza triangolare, la proprietà della sottostruttura minima e i problemi SSSP e APSP.
	
	\section{Metriche di valutazione}
	\label{section:metriche}
	Qui si parla delle metriche di valutazione adottate in questo progetto, si spiega che cosa misurano e cosa significano.
	
	\subsection{Speedup}
	Perchè è molto importante e perchè non ha senso misurarlo sulle applicazioni CUDA? Noi lo misureremo lo stesso ma solo rispetto alla versione seriale su CPU.
	
	\subsection{Throughput}
	\'E una metrica molto meglio rappresentativa delle prestazioni di un'applicazione CUDA perchè rappresenta il numero medio di "elementi" processati in un secondo o in un certo intervallo di tempo.
	
	\subsection{Intensità aritmetica}
	\'E una metrica per confrontare due implementazioni diverse dello stesso algoritmo. Si calcola come il rapporto tra il numero di byte coinvolti in tutti i calcoli e il numero di byte necessario per la memoria. Il valore ottenuto rappresenta "quanto l'implementazione X di un algoritmo sia computation-based o memory-based". Noi la utilizzeremo per spiegare meglio i valori ottenuti dalle misurazioni di speedup e throughput delle varie versioni dell'algoritmo.
	
	\section{Analisi}
	\label{section:analisi}
	\subsection{Algoritmo di Bellman-Ford}
	Proposto per primo da Alfonso Shimbel nel 1955\cite{Shimbel1955}, ma è chiamato Bellman-Ford perchè Richard Bellman l'ha pubblicato nel 1958\cite{Bellman1958} e Lester Ford Jr. l'ha pubblicato nel 1956\cite{Ford1956}. Edward F. Moore ha pubblicato una sua variante nel 1959\cite{Moore1959} (per questo a volte viene chiamato Bellman-Ford-Moore). La variante di Moore è nota come Shortest Path Faster Algorithm. Yen nel 1970\cite{Yen1970} ha proposto una nuova variante per ridurre il numero di passi di rilassamento. Bannister e Eppstein nel 2012\cite{Bannister2012} hanno proposto una nuova variante per ridurre ulteriormente i passi di rilassamento.
	
	\begin{algorithm}[H]
		\SetAlgorithmName{Bellman-Ford}{}{}
		\KwIn{G, w, s}
		\KwResult{FALSE se il grafo G contiene cicli di costo negativo, FALSE altrimenti}
		Initialize-Single-Source(G,s)\;
		\For{i=1 \textbf{to} |G.V| - 1}{
			\ForEach{edge (u,v) $\in$ G.E}{
				Relax(u,v,w)\;
			}
		}
		\ForEach{edge (u,v) $\in$ G.E}{
			\If{v.d > u.d + w(u,v)}{
				\Return FALSE\;
			}
		}
		\Return TRUE\;
		\caption{L'algoritmo di Bellman-Ford}
	\end{algorithm}

	\begin{algorithm}[H]
		\SetAlgorithmName{Initialize-Single-Source}{}{}
		\KwIn{G, s}
		\ForEach{vertex v $\in$ G.V}{
			v.d = $\infty$\;
			v.$\pi$ = NIL\;
		}
		s.d = 0\;
		\caption{La procedura di inizializzazione di un grafo}
	\end{algorithm}

	\begin{algorithm}[H]
		\SetAlgorithmName{Relax}{}{}
		\KwIn{u, v, w}
		\If{v.d > u.d + w(u,v)}{
			v.d = u.d + w(u,v)\;
			v.$\pi$ = u\;
		}
		\caption{La procedura Relax}
	\end{algorithm}
	
	\section{Design}
	\label{section:design}
	Qui si propongono alcune versioni parallele dell'algoritmo (e si etichettano per distinguerle tra loro) basandosi sull'analisi effettuata nel capitolo precedente
	
	\begin{itemize}
		\item \texttt{bf0}: memorizzare il grafo come array di archi e parallelizzare il ciclo interno ovvero il "per ogni arco del grafo" (usare un thread per ogni arco). In realtà questa versione si ramifica in altre 4 sotto-versioni che variano in base al meccanismo utilizzato per gestire le scritture concorrenti sul vettore \texttt{D}.
		\begin{itemize}
			\item \texttt{bf0-none}: non si utilizza nulla. Gli aggiornamenti dovrebbero essere così poco frequenti che il risultato potrebbe essere comunque corretto.
			\item \texttt{bf0-mutex}: usare una mutex per ogni nodo.
		\end{itemize}
	
		\item \texttt{bf1}: memorizzare il grafo come lista di adiacenza e parallelizzare il ciclo interno. Per ogni nodo $u$ si creano tanti thread quanti sono i nodi $v$ a cui è collegato (o semplicemente $N-1$ thread), ognuno di questi thread esegue il relax dell'arco uscente $(u,v)$ aggiornando \texttt{D[v]}. Questa versione usa molti meno thread della \texttt{bf0} ma non ha il problema della concorrenza.
		
		\item \texttt{bf2}: memorizzare il grafo come lista di adiacenza e parallelizzare il ciclo interno. Per ogni nodo $v$ si creano tanti thread quanti sono i nodi $u$ a cui è collegato (o semplicemente $N-1$ thread), ognuno di questi thread esegue il relax dell'arco entrante $(u,v)$ mantenendo un valore parziale, infine si opera una min-reduction per determinare \texttt{D[v]}. Questa versione usa molti meno thread della \texttt{bf0} ma non ha il problema della concorrenza.
	\end{itemize}
	
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Nome versione} & \textbf{Mutex} & \textbf{AoS/SoA} & \textbf{Shared Memory} \\ \hline
			\texttt{bf0-none-aos-nosh}  & no & AoS & no \\ \hline
			\texttt{bf0-none-aos-sh}    & no & AoS & si \\ \hline
			\texttt{bf0-none-soa-nosh}  & no & SoA & no \\ \hline
			\texttt{bf0-none-soa-sh}    & no & SoA & si \\ \hline
			\texttt{bf0-mutex-aos-nosh} & si & AoS & no \\ \hline
			\texttt{bf0-mutex-aos-sh}   & si & AoS & si \\ \hline
			\texttt{bf0-mutex-soa-nosh} & si & SoA & no \\ \hline
			\texttt{bf0-mutex-soa-sh}   & si & SoA & si \\ \hline
		\end{tabular}
		\label{tab:riassunto_bf0}
		\caption{Tabella riassuntiva delle caratteristiche delle sotto-versioni dell'algoritmo \texttt{bf0}}
	\end{table}

	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|}
			\hline
			\textbf{Nome versione} & \textbf{AoS/SoA} & \textbf{Shared Memory} \\ \hline
			\texttt{bf1-aos-nosh}  & AoS & no \\ \hline
			\texttt{bf1-aos-sh}    & AoS & si \\ \hline
			\texttt{bf1-soa-nosh}  & SoA & no \\ \hline
			\texttt{bf1-soa-sh}    & SoA & si \\ \hline
		\end{tabular}
		\label{tab:riassunto_bf1}
		\caption{Tabella riassuntiva delle caratteristiche delle sotto-versioni dell'algoritmo \texttt{bf1}}
	\end{table}

	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|}
			\hline
			\textbf{Nome versione} & \textbf{AoS/SoA} & \textbf{Shared Memory} \\ \hline
			\texttt{bf2-aos-nosh}  & AoS & no \\ \hline
			\texttt{bf2-aos-sh}    & AoS & si \\ \hline
			\texttt{bf2-soa-nosh}  & SoA & no \\ \hline
			\texttt{bf2-soa-sh}    & SoA & si \\ \hline
		\end{tabular}
		\label{tab:riassunto_bf2}
		\caption{Tabella riassuntiva delle caratteristiche delle sotto-versioni dell'algoritmo \texttt{bf2}}
	\end{table}
	
	\section{Dettagli implementativi}
	\label{section:impl}
	Serve fare un capitolo a parte per dei dettagli?
	
	Bisogna specificare che nei programmi della repo il nodo sorgente in ogni esecuzione dell'algoritmo è sempre il primo (quello di indice 0).
	
	O in questo capitolo o prima bisogna dire che, siccome per i nostri scopi non serve che l'algoritmo produca come risultato anche tutti i percorsi (nella forma di un vettore di predecessori) Bellman-Ford non è stato implementato in questo modo.
	
	Qui parlo del problema dell'overflow e della funzione atomicMin. Magari anche di come ho implementato le mutex nella versione \texttt{bf0-mutex}.
	
	Tutti gli algoritmi che utilizzano un buffer nella shared memory lo utilizzano per memorizzare i dati del "vettore \texttt{graph}" (invece del "vettore \texttt{distances}" oppure una soluzione ibrida) perchè si è rivelata la soluzione migliore e la più veloce a seguito di prove empiriche i cui risultati non sono riportati qui.
	
	La versione \texttt{bf0-none-aos-sh} usa un buffer shared per il vettore \texttt{graph} e non per il vettore \texttt{distances} perchè nel primo caso si ottiene un throughput fino a $1,121\cdot 10^9$ mentre nel secondo caso si raggiunge a fatica $1\cdot 10^9$ rilassamenti al secondo. Lo stesso discorso vale per tutte le altre versioni implementate, si utilizza la shared memory su graph (o sui vettori nel caso di \texttt{soa}) perchè produce un throughput maggiore rispetto a quando la si usa sul vettore \texttt{distances}. Qui andrebbe scritto qualcosa del tipo "nonostante in teoria un buffering del vettore \texttt{distances} riduce maggiormente il numero di accessi alla memoria globale, nella pratica gli accessi estremamenti sparsi su tutto il vettore producono un risultato molto più lento della versione senza shared memory.
	
	Aggiungere dettagli sui limiti delle varie versioni dell'algoritmo: ad esempio, le versioni \texttt{bf0}, siccome creano un thread per ogni arco, funzionano bene solo se il grafo ha meno di $2^{31}\cdot 1024$ archi (max numero di blocchi per max numero di thread). Le versioni \texttt{bf2} creano un blocco di thread per ogni nodo, quindi può gestire un grafo con massimo $2^{31}$ nodi.
	
	Le versioni \texttt{bf1} e \texttt{bf2} non funzionano bene su grafi con nodi isolati. In particolare, siccome l'algoritmo \texttt{bf1} memorizza il grafo come una lista di adiacenza degli archi uscenti, questi "non funziona bene" se è presente un nodo senza archi uscenti. Lo stesso discorso vale per \texttt{bf2} ma con gli archi entranti. Invece l'algoritmo \texttt{bf0} semplicemente produrrà un valore di $+\infty$ per tutti i nodi irraggiungibili.
	
	\section{Valutazione delle prestazioni}
	\label{section:perf}
	I test di correttezza di ogni versione vanno effettuati su ogni test disponibile. Ovviamente, solo le versioni che producono un risultato corretto in tutti i casi vengono tenute in considerazione nei capitoli successivi. I test per la valutazione delle prestazioni, invece, possono essere eseguiti solo sul test più voluminoso per ridurre i tempi di valutazione.
	
	\subsection{Dati della macchina su cui misuriamo l'algoritmo seriale}
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			& \textbf{Macchina A} & \textbf{Macchina B} & \textbf{Macchina C} \\ \hline
			\textbf{Sistema Operativo} & Windows & Ubuntu & Windows \\ \hline
			\textbf{Versione SO} & 10.0.19042.1165 & 16.04.7 & 10.0.19043.1165 \\ \hline
			\textbf{Versione Compilatore C} & CL 19.29.30133 & GCC 5.4.0 & CL 19.29.30040 \\ \hline
			\textbf{Nome CPU} & Intel Core i5-7200U & Intel Xeon E5-2603 v4 & Intel Core i7-8700 \\ \hline
			\textbf{Frequenza CPU} & 2,5 - 2,7 GHz & 1,2 - 1,7 GHz & 3,2 GHz \\ \hline
			\textbf{Cores fisici} & 2 & 6 & 6 \\ \hline
			\textbf{Hyper-Threading} & si & no & si \\ \hline
			\textbf{L1 cache} & 128 KB & 32 KB & 384 KB \\ \hline
			\textbf{L2 cache} & 512 KB & 256 KB & 1,5 MB \\ \hline
			\textbf{L3 cache} & 3 MB & 15 MB & 12 MB \\ \hline
			\textbf{RAM totale} & 8 GB & 64 GB & 32 GB \\ \hline
			\textbf{Frequenza RAM} & 2133 MHz & & 2133 MHz \\ \hline
			\textbf{Tipologia RAM} & DDR4 & & DDR4 \\ \hline
			\textbf{Nome GPU} & \textbf{GeForce 940MX} & \textbf{GeForce GTX 1070} & \textbf{GeForce RTX 2080} \\ \hline
			\textbf{Versione CUDA Driver} & 11.4 & 10.1 & 11.4 \\ \hline
			\textbf{Versione CUDA Runtime} & 11.1 & 8.0 & 11.1 \\ \hline
			\textbf{CUDA compute capability} & 5.0 & 6.1 & 7.5 \\ \hline
			\textbf{Architettura GPU} & Maxwell & Pascal & Turing \\ \hline
			\textbf{Memoria globale GPU} & 2 GB & 8 GB & 8 GB \\ \hline
			\textbf{Tipologia Memoria GPU} & GDDR5 & GDDR5 & GDDR6 \\ \hline
			\textbf{Frequenza Memoria} & 2505 MHz & 4004 MHz & 7000 MHz \\ \hline
			\textbf{Ampiezza Bus GPU} & 64 bit & 256 bit & 256 bit \\ \hline
			\textbf{Streaming Multiprocessors} & 3 & 15 & 46 \\ \hline
			\textbf{CUDA cores totali} & 384 & 1920 & 2944 \\ \hline
			\textbf{Frequenza Cores} & 1189 MHz & 1797 MHz & 1860 MHz \\ \hline
		\end{tabular}
		\label{tab:specs}
		\caption{Specifiche delle macchine su cui effettuiamo le misurazioni}
	\end{table}

	\subsection{Performance dell'algoritmo seriale}
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|c|c|c|}
			\hline
			\textbf{Nome test} & \textbf{Wall Clock Time [s]} & \textbf{Throughput [$10^6$ relax/s]} \\ \hline
			       rome & 0,38 & 78 \\ \hline
			        DE & 81,45 & 75 \\ \hline
			        VT & 217,06 & 95,8 \\ \hline
			        ME & 874,61 & 94 \\ \hline
			        NV & 1743,02 & 92 \\ \hline
			        025 & 2,39 & 104,2 \\ \hline
			        050 & 4,55 & 109,4 \\ \hline
			        075 & 6,8 & 109,8 \\ \hline
			        100 & 8,12 & 122,4 \\ \hline
		\end{tabular}
		\label{tab:performance_serial}
		\caption{Prestazioni dell'algoritmo seriale su CPU (sulla "macchina A")}
	\end{table}

	\subsection{Descrizione dei test}
	Qui parlo di come sono strutturati i file di test e cosa rappresentano.
	
	Tutti i valori riportati nelle tabelle sono ottenuti misurandoli sul test più voluminoso (NV). Le tabelle complete saranno inserite come file Excel a parte dentro la repo.
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			\textbf{Nome test} & \textbf{Numero nodi} & \textbf{Numero archi} & \textbf{Descrizione} \\ \hline
			rome & 3353 & 8859 & Mappa metropolitana di Roma \\ \hline
			DE & 49109 & 119744 & Mappa stradale del Delaware \\ \hline
			VT & 97975 & 212979 & Mappa stradale del Vermont \\ \hline
			ME & 194505 & 425708 & Mappa stradale del Maine \\ \hline
			NV & 261155 & 618175 & Mappa stradale del Nevada \\ \hline
			025 & 1000 & 249808 & Grafo casuale con densità 0.25 \\ \hline
			050 & 1000 & 499574 & Grafo casuale con densità 0.5 \\ \hline
			075 & 1000 & 749262 & Grafo casuale con densità 0.75 \\ \hline
			100 & 1000 & 999000 & Grafo casuale completo \\ \hline
		\end{tabular}
		\label{tab:riassunto_test}
		\caption{Tabella riassuntiva delle specifiche dei test utilizzati}
	\end{table}

	\subsection{Correttezza degli algoritmi}
	Qui dobbiamo scartare le eventuali versioni che non producono un risultato corretto su tutti i test disponibili.
	
	Tutti gli algoritmi producono il risultato corretto sul grafo di Roma, tranne \texttt{bf2-soa-sh}.
	
	\subsection{Speedup}
	Di seguito riportiamo i valori di speedup di ogni versione, rispetto al tempo d'esecuzione dell'algoritmo \texttt{bf-serial}, misurati su ogni scheda.
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Nome algoritmo} & \textbf{940MX} & \textbf{GTX 1070} & \textbf{RTX 2080} \\ \hline
			\texttt{bf0-none-aos-nosh}  &  &  &  \\ \hline
			\texttt{bf0-none-aos-sh}    &  &  &  \\ \hline
			\texttt{bf0-none-soa-nosh}  &  &  &  \\ \hline
			\texttt{bf0-none-soa-sh}    &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-nosh} &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-sh}   &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-nosh} &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-sh}   &  &  &  \\ \hline
		\end{tabular}
		\label{tab:speedup_bf0}
		\caption{Misurazioni dello speedup per le versioni dell'algoritmo \texttt{bf0}}
	\end{table}

	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Nome algoritmo} & \textbf{940MX} & \textbf{GTX 1070} & \textbf{RTX 2080} \\ \hline
			\texttt{bf1-aos-nosh}  &  &  &  \\ \hline
			\texttt{bf1-aos-sh}    &  &  &  \\ \hline
			\texttt{bf1-soa-nosh}  &  &  &  \\ \hline
			\texttt{bf1-soa-sh}    &  &  &  \\ \hline
		\end{tabular}
		\label{tab:speedup_bf1}
		\caption{Misurazioni dello speedup per le versioni dell'algoritmo \texttt{bf1}}
	\end{table}

	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Nome algoritmo} & \textbf{940MX} & \textbf{GTX 1070} & \textbf{RTX 2080} \\ \hline
			\texttt{bf2-aos-nosh}  &  &  &  \\ \hline
			\texttt{bf2-aos-sh}    &  &  &  \\ \hline
			\texttt{bf2-soa-nosh}  &  &  &  \\ \hline
			\texttt{bf2-soa-sh}    & N/A & N/A & N/A \\ \hline
		\end{tabular}
		\label{tab:speedup_bf2}
		\caption{Misurazioni dello speedup per le versioni dell'algoritmo \texttt{bf2}}
	\end{table}
	
	\subsection{Throughput}
	Di seguito riportiamo i valori di throughput di ogni versione, indicati come numero di rilassamenti al secondo, misurati su ogni scheda.
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Nome versione} & \textbf{940MX} & \textbf{GTX 1070} & \textbf{RTX 2080} \\ \hline
			\texttt{bf0-none-aos-nosh}  &  &  &  \\ \hline
			\texttt{bf0-none-aos-sh}    &  &  &  \\ \hline
			\texttt{bf0-none-soa-nosh}  &  &  &  \\ \hline
			\texttt{bf0-none-soa-sh}    &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-nosh} &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-sh}   &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-nosh} &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-sh}   &  &  &  \\ \hline
		\end{tabular}
		\label{tab:throughput_bf0}
		\caption{Misurazioni del throughput per le versioni dell'algoritmo \texttt{bf0}}
	\end{table}

	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Nome algoritmo} & \textbf{940MX} & \textbf{GTX 1070} & \textbf{RTX 2080} \\ \hline
			\texttt{bf1-aos-nosh}  &  &  &  \\ \hline
			\texttt{bf1-aos-sh}    &  &  &  \\ \hline
			\texttt{bf1-soa-nosh}  &  &  &  \\ \hline
			\texttt{bf1-soa-sh}    &  &  &  \\ \hline
		\end{tabular}
		\label{tab:throughput_bf1}
		\caption{Misurazioni del throughput per le versioni dell'algoritmo \texttt{bf1}}
	\end{table}
	
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Nome algoritmo} & \textbf{940MX} & \textbf{GTX 1070} & \textbf{RTX 2080} \\ \hline
			\texttt{bf2-aos-nosh}  &  &  &  \\ \hline
			\texttt{bf2-aos-sh}    &  &  &  \\ \hline
			\texttt{bf2-soa-nosh}  &  &  &  \\ \hline
			\texttt{bf2-soa-sh}    & N/A & N/A & N/A \\ \hline
		\end{tabular}
		\label{tab:throughput_bf2}
		\caption{Misurazioni del throughput per le versioni dell'algoritmo \texttt{bf2}}
	\end{table}
	
	
	
	Fonte dei test:
	\begin{itemize}
		\item \url{https://www.moreno.marzolla.name/teaching/LabASD/handouts/bellman-ford.html}
		\item \url{http://users.diag.uniroma1.it/challenge9/download.shtml}
	\end{itemize}
	
	\section{Conclusioni}
	\label{section:end}
	Qui dovrei effettuare un'analisi di tutti i risultati ottenuti e scegliere infine la versione migliore da etichettare come "Bellman-Ford in CUDA".
	
	\printbibliography
	
\end{document}