\documentclass{article}

\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage[
backend=biber,
style=alphabetic,
sorting=ynt
]{biblatex}
\usepackage[linesnumbered, ruled, titlenotnumbered]{algorithm2e}

\addbibresource{tesi.bib}

\title{Implementazione CUDA dell'algoritmo di Bellman-Ford}
\author{Filippo Barbari}
\date{\today}

\begin{document}
	
	\maketitle
	\newpage
	
	\tableofcontents
	\newpage
	
	\listoffigures
	\newpage
	
	\listoftables
	\newpage
	
	\listofalgorithms
	\newpage
	
	\section{Introduzione}
	L'obiettivo di questa tesi consiste in...
	
	Il capitolo \ref{section:storia} è un'introduzione al calcolo parallelo: alcuni cenni storici, l'evoluzione dell'hardware fino ai giorni nostri e le strade verso cui potrebbe dirigersi. Nel capitolo \ref{section:analisi} si analizza il problema del Single-Source Shortest Path e poi l'algoritmo proposto da Bellman e Ford. Nella stessa sezione, inoltre, si mostra la sua correttezza e i suoi pregi e difetti. Nella sezione \ref{section:design}, partendo dall'analisi del capitolo precedente, si enumerano (?) un insieme di possibili parallelizzazioni dell'algoritmo spiegando quale potrebbe essere la migliore e perchè. Nel capitolo \ref{section:impl} si discuterà dei dettagli implementativi non trascurabili che saranno presenti nella repo. Infine, nel capitolo \ref{section:perf} si mostreranno i risultati delle misure più comuni che è possibile misurare su GPU (throughput, bandwidth...?) e si discuteranno.
	
	\section{Calcolo parallelo}
	\label{section:storia}
	Qui si parla della storia del calcolo parallelo, perchè è necessario, perchè si sta sviluppando così tanto e perchè le GPU sono diventate cosi importanti.
	
	\section{GPU e CUDA}
	\label{section:cuda}
	Qui si parla di cos'è CUDA e come funziona. Si parla anche della struttura della memoria di una GPU CUDA e di come funziona lo scheduling.
	
	\section{Metriche di valutazione}
	\label{section:metriche}
	Qui si parla delle metriche di valutazione adottate in questo progetto, si spiega che cosa misurano e cosa significano.
	
	\section{Analisi}
	\label{section:analisi}
	\subsection{Notazione}
	\subsection{Single-Source Shortest Path problem}
	\subsection{Algoritmo di Bellman-Ford}
	Proposto per primo da Alfonso Shimbel nel 1955, ma è chiamato Bellman-Ford perchè Richard Bellman l'ha pubblicato nel 1958 e Lester Ford Jr. l'ha pubblicato nel 1956. Edward F. Moore ha pubblicato una sua variante nel 1959 (per questo a volte viene chiamato Bellman-Ford-Moore). La variante di Moore è nota come Shortest Path Faster Algorithm. Yen nel 1970 ha proposto una nuova variante per ridurre il numero di passi di rilassamento. Bannister e Eppstein nel 2012 hanno proposto una nuova variante per ridurre ulteriormente i passi di rilassamento.
	
	\begin{algorithm}[H]
		\SetAlgorithmName{Bellman-Ford}{}{}
		\KwIn{G, w, s}
		\KwResult{FALSE se il grafo G contiene cicli di costo negativo, FALSE altrimenti}
		Initialize-Single-Source(G,s)\;
		\For{i=1 \textbf{to} |G.V| - 1}{
			\ForEach{edge (u,v) $\in$ G.E}{
				Relax(u,v,w)\;
			}
		}
		\ForEach{edge (u,v) $\in$ G.E}{
			\If{v.d > u.d + w(u,v)}{
				\Return FALSE\;
			}
		}
		\Return TRUE\;
		\caption{L'algoritmo di Bellman-Ford}
	\end{algorithm}

	\begin{algorithm}[H]
		\SetAlgorithmName{Initialize-Single-Source}{}{}
		\KwIn{G, s}
		\ForEach{vertex v $\in$ G.V}{
			v.d = $\infty$\;
			v.$\pi$ = NIL\;
		}
		s.d = 0\;
		\caption{La procedura di inizializzazione di un grafo}
	\end{algorithm}

	\begin{algorithm}[H]
		\SetAlgorithmName{Relax}{}{}
		\KwIn{u, v, w}
		\If{v.d > u.d + w(u,v)}{
			v.d = u.d + w(u,v)\;
			v.$\pi$ = u\;
		}
		\caption{La procedura Relax}
	\end{algorithm}
	
	\section{Design}
	\label{section:design}
	Qui si propongono alcune versioni parallele dell'algoritmo (e si etichettano per distinguerle tra loro) basandosi sull'analisi effettuata nel capitolo precedente
	
	\begin{itemize}
		\item \texttt{bf0}: memorizzare il grafo come array di archi e parallelizzare il ciclo interno ovvero il "per ogni arco del grafo" (usare un thread per ogni arco). In realtà questa versione si ramifica in altre 4 sotto-versioni che variano in base al meccanismo utilizzato per gestire le scritture concorrenti sul vettore \texttt{D}.
		\begin{itemize}
			\item \texttt{bf0-none}: non si utilizza nulla. Gli aggiornamenti dovrebbero essere così poco frequenti che il risultato potrebbe essere comunque corretto. La versione "single-step" produce il risultato corretto sul grafo di Roma, quella non "single-step" produce un risultato di poco diverso (in tutto qualche centinaio di nodi hanno un valore errato).
			\item \texttt{bf0-mutex}: usare una mutex per ogni nodo. Sul grafo di Roma, la versione "single-step" produce il risultato corretto, quella non "single-step" produce un risultato molto diverso.
			\item \texttt{bf0-min}: usare l'istruzione CUDA \texttt{atomicMin}.
			\item \texttt{bf0-minred}: utilizza una min-reduction per evitare aggiornamenti concorrenti. (come alternativa a \texttt{bf0-min})
		\end{itemize}
	
		\item \texttt{bf1}: memorizzare il grafo come lista di adiacenza (in realtà non serve) e parallelizzare il ciclo interno. Per ogni nodo $u$ si creano tanti thread quanti sono i nodi $v$ a cui è collegato (o semplicemente $N-1$ thread), ognuno di questi thread esegue il relax dell'arco uscente $(u,v)$ aggiornando \texttt{D[v]}. Questa versione usa molti meno thread della \texttt{bf0} ma non ha il problema della concorrenza.
		
		\item \texttt{bf2}: memorizzare il grafo come lista di adiacenza (in realtà non serve) e parallelizzare il ciclo interno. Per ogni nodo $v$ si creano tanti thread quanti sono i nodi $u$ a cui è collegato (o semplicemente $N-1$ thread), ognuno di questi thread esegue il relax dell'arco entrante $(u,v)$ mantenendo un valore parziale, infine si opera una min-reduction per determinare \texttt{D[v]}. Questa versione usa molti meno thread della \texttt{bf0} ma non ha il problema della concorrenza.
	\end{itemize}

	In ogni caso, per ognuna di queste versioni, bisognerebbe provare la versione shared memory e le versione AoS e SoA. Per ottimizzare gli accessi si potrebbe provare a sortare gli archi in base all'esigenza.
	
	Alla fine di questo capitolo si possono aggiungere alcuni dettagli implementativi da discutere come l'implementazione "step" (per la sincronizzazione) oppure quella "normale".
	
	\section{Dettagli implementativi}
	\label{section:impl}
	Serve fare un capitolo a parte per dei dettagli?
	
	Qui parlo del problema dell'overflow e della funzione atomicMin. Magari anche di come ho implementato le mutex nella versione \texttt{bf0-mutex}.
	
	La versione \texttt{bf0-none-aos-sh} usa un buffer shared per il vettore \texttt{graph} e non per il vettore \texttt{distances} perchè nel primo caso si ottiene un throughput fino a $1,121\cdot 10^9$ mentre nel secondo caso si raggiunge a fatica $1\cdot 10^9$ rilassamenti al secondo.
	
	\section{Valutazione delle prestazioni}
	\label{section:perf}
	I test di correttezza di ogni versione vanno effettuati su ogni test disponibile. Ovviamente, solo le versioni che producono un risultato corretto in tutti i casi vengono tenute in considerazione nei capitoli successivi. I test per la valutazione delle prestazioni, invece, possono essere eseguiti solo sul test più voluminoso per ridurre i tempi di valutazione.
	
	\subsection{Throughput}
	\subsection{Bandwidth}
	Fonte dei test:
	\begin{itemize}
		\item \url{https://www.moreno.marzolla.name/teaching/LabASD/handouts/bellman-ford.html}
		\item \url{http://users.diag.uniroma1.it/challenge9/download.shtml}
	\end{itemize}
	
	\section{Conclusioni}
	\label{section:end}
	
	\printbibliography
	
\end{document}