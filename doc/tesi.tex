\documentclass{article}

\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage[
backend=biber,
style=alphabetic,
sorting=ynt
]{biblatex}
\usepackage[linesnumbered, ruled, titlenotnumbered]{algorithm2e}

\addbibresource{tesi.bib}

\renewcommand{\arraystretch}{1.2}

\title{Implementazione CUDA dell'algoritmo di Bellman-Ford}
\author{Filippo Barbari}
\date{\today}

\begin{document}
	
	\maketitle
	\newpage
	
	\tableofcontents
	\newpage
	
	\listoffigures
	\newpage
	
	\listoftables
	\newpage
	
	\listofalgorithms
	\newpage
	
	\section{Introduzione}
	L'obiettivo di questa tesi consiste nell'implementazione in linguaggio CUDA dell'algoritmo di Bellman-Ford per il Single-Source Shortest Path problem.
	
	Il capitolo \ref{section:storia} è un'introduzione al calcolo parallelo: alcuni cenni storici, l'evoluzione dell'hardware fino ai giorni nostri e le strade verso cui potrebbe dirigersi. Nel capitolo \ref{section:analisi} si analizza il problema del Single-Source Shortest Path e poi l'algoritmo proposto da Bellman e Ford. Nella stessa sezione, inoltre, si mostra la sua correttezza e i suoi pregi e difetti. Nella sezione \ref{section:design}, partendo dall'analisi del capitolo precedente, si enumerano (?) un insieme di possibili parallelizzazioni dell'algoritmo spiegando quale potrebbe essere la migliore e perchè. Nel capitolo \ref{section:impl} si discuterà dei dettagli implementativi non trascurabili che saranno presenti nella repo. Infine, nel capitolo \ref{section:perf} si mostreranno i risultati delle misure più comuni che è possibile misurare su GPU (throughput, bandwidth...?) e si discuteranno.
	
	\section{Calcolo parallelo}
	\label{section:storia}
	Qui si parla della storia del calcolo parallelo, perchè è necessario, perchè si sta sviluppando così tanto e perchè le GPU sono diventate cosi importanti.
	
	\section{GPU e CUDA}
	\label{section:cuda}
	Serve un capitolo a parte o si può fare un sotto-capitolo dei cenni storici?
	Qui si parla di cos'è CUDA e come funziona. Si parla anche della struttura della memoria di una GPU CUDA e di come funziona lo scheduling.
	
	\section{Metriche di valutazione}
	\label{section:metriche}
	Qui si parla delle metriche di valutazione adottate in questo progetto, si spiega che cosa misurano e cosa significano.
	
	\subsection{Speedup}
	Perchè è molto importante e perchè non ha senso misurarlo sulle applicazioni CUDA? Noi lo misureremo lo stesso ma solo rispetto alla versione seriale su CPU.
	
	\subsection{Throughput}
	\'E una metrica molto meglio rappresentativa delle prestazioni di un'applicazione CUDA perchè rappresenta il numero medio di "elementi" processati in un secondo o in un certo intervallo di tempo.
	
	\subsection{Intensità aritmetica}
	\'E una metrica per confrontare due implementazioni diverse dello stesso algoritmo. Si calcola come il rapporto tra il numero di byte coinvolti in tutti i calcoli e il numero di byte necessario per la memoria. Il valore ottenuto rappresenta "quanto l'implementazione X di un algoritmo sia computation-based o memory-based". Noi la utilizzeremo per spiegare meglio i valori ottenuti dalle misurazioni di speedup e throughput delle varie versioni dell'algoritmo.
	
	\section{Analisi}
	\label{section:analisi}
	\subsection{Notazione}
	\subsection{Single-Source Shortest Path problem}
	\subsection{Algoritmo di Bellman-Ford}
	Proposto per primo da Alfonso Shimbel nel 1955, ma è chiamato Bellman-Ford perchè Richard Bellman l'ha pubblicato nel 1958 e Lester Ford Jr. l'ha pubblicato nel 1956. Edward F. Moore ha pubblicato una sua variante nel 1959 (per questo a volte viene chiamato Bellman-Ford-Moore). La variante di Moore è nota come Shortest Path Faster Algorithm. Yen nel 1970 ha proposto una nuova variante per ridurre il numero di passi di rilassamento. Bannister e Eppstein nel 2012 hanno proposto una nuova variante per ridurre ulteriormente i passi di rilassamento.
	
	\begin{algorithm}[H]
		\SetAlgorithmName{Bellman-Ford}{}{}
		\KwIn{G, w, s}
		\KwResult{FALSE se il grafo G contiene cicli di costo negativo, FALSE altrimenti}
		Initialize-Single-Source(G,s)\;
		\For{i=1 \textbf{to} |G.V| - 1}{
			\ForEach{edge (u,v) $\in$ G.E}{
				Relax(u,v,w)\;
			}
		}
		\ForEach{edge (u,v) $\in$ G.E}{
			\If{v.d > u.d + w(u,v)}{
				\Return FALSE\;
			}
		}
		\Return TRUE\;
		\caption{L'algoritmo di Bellman-Ford}
	\end{algorithm}

	\begin{algorithm}[H]
		\SetAlgorithmName{Initialize-Single-Source}{}{}
		\KwIn{G, s}
		\ForEach{vertex v $\in$ G.V}{
			v.d = $\infty$\;
			v.$\pi$ = NIL\;
		}
		s.d = 0\;
		\caption{La procedura di inizializzazione di un grafo}
	\end{algorithm}

	\begin{algorithm}[H]
		\SetAlgorithmName{Relax}{}{}
		\KwIn{u, v, w}
		\If{v.d > u.d + w(u,v)}{
			v.d = u.d + w(u,v)\;
			v.$\pi$ = u\;
		}
		\caption{La procedura Relax}
	\end{algorithm}
	
	\section{Design}
	\label{section:design}
	Qui si propongono alcune versioni parallele dell'algoritmo (e si etichettano per distinguerle tra loro) basandosi sull'analisi effettuata nel capitolo precedente
	
	\begin{itemize}
		\item \texttt{bf0}: memorizzare il grafo come array di archi e parallelizzare il ciclo interno ovvero il "per ogni arco del grafo" (usare un thread per ogni arco). In realtà questa versione si ramifica in altre 4 sotto-versioni che variano in base al meccanismo utilizzato per gestire le scritture concorrenti sul vettore \texttt{D}.
		\begin{itemize}
			\item \texttt{bf0-none}: non si utilizza nulla. Gli aggiornamenti dovrebbero essere così poco frequenti che il risultato potrebbe essere comunque corretto. La versione "single-step" produce il risultato corretto sul grafo di Roma, quella non "single-step" produce un risultato di poco diverso (in tutto qualche centinaio di nodi hanno un valore errato).
			\item \texttt{bf0-mutex}: usare una mutex per ogni nodo. Sul grafo di Roma, la versione "single-step" produce il risultato corretto, quella non "single-step" produce un risultato molto diverso.
		\end{itemize}
	
		\item \texttt{bf1}: memorizzare il grafo come lista di adiacenza (in realtà non serve) e parallelizzare il ciclo interno. Per ogni nodo $u$ si creano tanti thread quanti sono i nodi $v$ a cui è collegato (o semplicemente $N-1$ thread), ognuno di questi thread esegue il relax dell'arco uscente $(u,v)$ aggiornando \texttt{D[v]}. Questa versione usa molti meno thread della \texttt{bf0} ma non ha il problema della concorrenza.
		
		\item \texttt{bf2}: memorizzare il grafo come lista di adiacenza (in realtà non serve) e parallelizzare il ciclo interno. Per ogni nodo $v$ si creano tanti thread quanti sono i nodi $u$ a cui è collegato (o semplicemente $N-1$ thread), ognuno di questi thread esegue il relax dell'arco entrante $(u,v)$ mantenendo un valore parziale, infine si opera una min-reduction per determinare \texttt{D[v]}. Questa versione usa molti meno thread della \texttt{bf0} ma non ha il problema della concorrenza.
	\end{itemize}

	In ogni caso, per ognuna di queste versioni, bisognerebbe provare la versione shared memory e le versione AoS e SoA. Per ottimizzare gli accessi si potrebbe provare a sortare gli archi in base all'esigenza.
	
	Alla fine di questo capitolo si possono aggiungere alcuni dettagli implementativi da discutere come l'implementazione "step" (per la sincronizzazione) oppure quella "normale".
	
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|c|}
			\hline
			\textbf{Nome versione} & \textbf{Kernel Type} & \textbf{Mutex} & \textbf{AoS/SoA} & \textbf{Shared Memory} \\ \hline
			\texttt{bf0-none-aos-nosh-step}  & step & no & AoS & no \\ \hline
			\texttt{bf0-none-aos-sh-step}    & step & no & AoS & si \\ \hline
			\texttt{bf0-none-soa-nosh-step}  & step & no & SoA & no \\ \hline
			\texttt{bf0-none-soa-sh-step}    & step & no & SoA & si \\ \hline
			\texttt{bf0-mutex-aos-nosh-step} & step & si & AoS & no \\ \hline
			\texttt{bf0-mutex-aos-sh-step}   & step & si & AoS & si \\ \hline
			\texttt{bf0-mutex-soa-nosh-step} & step & si & SoA & no \\ \hline
			\texttt{bf0-mutex-soa-sh-step}   & step & si & SoA & si \\ \hline
			\texttt{bf0-none-aos-nosh-full}  & full & no & AoS & no \\ \hline
			\texttt{bf0-none-aos-sh-full}    & full & no & AoS & si \\ \hline
			\texttt{bf0-none-soa-nosh-full}  & full & no & SoA & no \\ \hline
			\texttt{bf0-none-soa-sh-full}    & full & no & SoA & si \\ \hline
			\texttt{bf0-mutex-aos-nosh-full} & full & si & AoS & no \\ \hline
			\texttt{bf0-mutex-aos-sh-full}   & full & si & AoS & si \\ \hline
			\texttt{bf0-mutex-soa-nosh-full} & full & si & SoA & no \\ \hline
			\texttt{bf0-mutex-soa-sh-full}   & full & si & SoA & si \\ \hline
		\end{tabular}
	\end{table}
	
	\section{Dettagli implementativi}
	\label{section:impl}
	Serve fare un capitolo a parte per dei dettagli?
	
	Bisogna specificare che nei programmi della repo il nodo sorgente in ogni esecuzione dell'algoritmo è sempre il primo (quello di indice 0).
	
	O in questo capitolo o prima bisogna dire che, siccome per i nostri scopi non serve che l'algoritmo produca come risultato anche tutti i percorsi (nella forma di un vettore di predecessori) Bellman-Ford non è stato implementato in questo modo.
	
	Qui parlo del problema dell'overflow e della funzione atomicMin. Magari anche di come ho implementato le mutex nella versione \texttt{bf0-mutex}.
	
	La versione \texttt{bf0-none-aos-sh} usa un buffer shared per il vettore \texttt{graph} e non per il vettore \texttt{distances} perchè nel primo caso si ottiene un throughput fino a $1,121\cdot 10^9$ mentre nel secondo caso si raggiunge a fatica $1\cdot 10^9$ rilassamenti al secondo.
	
	\section{Valutazione delle prestazioni}
	\label{section:perf}
	I test di correttezza di ogni versione vanno effettuati su ogni test disponibile. Ovviamente, solo le versioni che producono un risultato corretto in tutti i casi vengono tenute in considerazione nei capitoli successivi. I test per la valutazione delle prestazioni, invece, possono essere eseguiti solo sul test più voluminoso per ridurre i tempi di valutazione.
	
	\subsection{Dati della macchina su cui misuriamo l'algoritmo seriale}
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|}
			\hline
			\textbf{Nome CPU} & Intel Core i5-7200U \\ \hline
			\textbf{Frequenza CPU} & 2,5 - 2,7 GHz \\ \hline
			\textbf{Core fisici} & 2 \\ \hline
			\textbf{Hyper-Threading} & si \\ \hline
			\textbf{L1 cache} & 128 KB \\ \hline
			\textbf{L2 cache} & 512 KB \\ \hline
			\textbf{L3 cache} & 3 MB \\ \hline
			\textbf{RAM totale} & 8 GB \\ \hline
			\textbf{Frequenza RAM} & 2133 MHz \\ \hline
			\textbf{Tipologia RAM} & DDR4 \\ \hline
		\end{tabular}
	\end{table}

	\subsection{Performance dell'algoritmo seriale}
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|c|c|c|}
			\hline
			\textbf{Nome test} & \textbf{Speedup} & \textbf{Throughput} \\ \hline
			rome &  &  \\ \hline
			DE &  &  \\ \hline
			VT &  &  \\ \hline
			ME &  &  \\ \hline
			NV &  &  \\ \hline
		\end{tabular}
	\end{table}
	
	\subsection{Schede su cui effettuiamo le misurazioni}
	Non serve veramente un capitoletto a sè.
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			  & \textbf{940MX} & \textbf{GTX 1070} & \textbf{RTX 2080} \\ \hline
			\textbf{CUDA Driver Version} & 11.4 & 10.1 & 11.4 \\ \hline
			\textbf{CUDA Runtime Version} & 11.1 & 8.0 & 11.1 \\ \hline
			\textbf{CUDA capability} & 5.0 & 6.1 & 7.5 \\ \hline
			\textbf{Architettura} & Maxwell & Pascal & Turing \\ \hline
			\textbf{Memoria globale (GB)} & 2 & 8 & 8 \\ \hline
			\textbf{Tipologia Memoria} & GDDR5 & GDDR5 & GDDR6 \\ \hline
			\textbf{Frequenza Memoria (MHz)} & 2505 & 4004 & 7000 \\ \hline
			\textbf{Memory Bus (bit)} & 64 & 256 & 256 \\ \hline
			\textbf{Streaming Multiprocessors} & 3 & 15 & 46 \\ \hline
			\textbf{Total CUDA Cores} & 384 & 1920 & 2944 \\ \hline
			\textbf{Frequenza Cores (MHz)} & 1189 & 1797 & 1860 \\ \hline
		\end{tabular}
	\end{table}

	\subsection{Descrizione dei test}
	Qui parlo di come sono strutturati i file di test e cosa rappresentano.
	
	Tutti i valori riportati nelle tabelle sono ottenuti misurandoli sul test più voluminoso (NV). Le tabelle complete saranno inserite come file Excel a parte dentro la repo.
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			\textbf{Nome test} & \textbf{Numero nodi} & \textbf{Numero archi} & \textbf{Descrizione} \\ \hline
			rome & 3353 & 8859 & Mappa metropolitana di Roma \\ \hline
			DE & 49109 & 119744 & Mappa stradale del Delaware \\ \hline
			VT & 97975 & 212979 & Mappa stradale del Vermont \\ \hline
			ME & 194505 & 425708 & Mappa stradale del Maine \\ \hline
			NV & 261155 & 618175 & Mappa stradale del Nevada \\ \hline
		\end{tabular}
	\end{table}

	\subsection{Correttezza degli algoritmi}
	Qui dobbiamo scartare le eventuali versioni che non producono un risultato corretto su tutti i test disponibili.
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|c|c|}
			\hline
			\textbf{Nome versione} & \textbf{rome} & \textbf{DE} & \textbf{VT} & \textbf{ME} & \textbf{NV} \\ \hline
			\texttt{bf0-none-aos-nosh-step}  &  &  &  &  &  \\ \hline
			\texttt{bf0-none-aos-sh-step}    &  &  &  &  &  \\ \hline
			\texttt{bf0-none-soa-nosh-step}  &  &  &  &  &  \\ \hline
			\texttt{bf0-none-soa-sh-step}    &  &  &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-nosh-step} &  &  &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-sh-step}   &  &  &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-nosh-step} &  &  &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-sh-step}   &  &  &  &  &  \\ \hline
			\texttt{bf0-none-aos-nosh-full}  &  &  &  &  &  \\ \hline
			\texttt{bf0-none-aos-sh-full}    &  &  &  &  &  \\ \hline
			\texttt{bf0-none-soa-nosh-full}  &  &  &  &  &  \\ \hline
			\texttt{bf0-none-soa-sh-full}    &  &  &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-nosh-full} &  &  &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-sh-full}   &  &  &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-nosh-full} &  &  &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-sh-full}   &  &  &  &  &  \\ \hline
		\end{tabular}
	\end{table}
	
	\subsection{Speedup}
	Di seguito riportiamo i valori di speedup di ogni versione, rispetto al tempo d'esecuzione dell'algoritmo \texttt{bf-serial}, misurati su ogni scheda.
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Nome versione} & \textbf{940MX} & \textbf{GTX 1070} & \textbf{RTX 2080} \\ \hline
			\texttt{bf0-none-aos-nosh-step}  &  &  &  \\ \hline
			\texttt{bf0-none-aos-sh-step}    &  &  &  \\ \hline
			\texttt{bf0-none-soa-nosh-step}  &  &  &  \\ \hline
			\texttt{bf0-none-soa-sh-step}    &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-nosh-step} &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-sh-step}   &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-nosh-step} &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-sh-step}   &  &  &  \\ \hline
			\texttt{bf0-none-aos-nosh-full}  & N/A &  &  \\ \hline
			\texttt{bf0-none-aos-sh-full}    & N/A &  &  \\ \hline
			\texttt{bf0-none-soa-nosh-full}  & N/A &  &  \\ \hline
			\texttt{bf0-none-soa-sh-full}    & N/A &  &  \\ \hline
			\texttt{bf0-mutex-aos-nosh-full} & N/A &  &  \\ \hline
			\texttt{bf0-mutex-aos-sh-full}   & N/A &  &  \\ \hline
			\texttt{bf0-mutex-soa-nosh-full} & N/A &  &  \\ \hline
			\texttt{bf0-mutex-soa-sh-full}   & N/A &  &  \\ \hline
		\end{tabular}
	\end{table}
	
	\subsection{Throughput}
	Di seguito riportiamo i valori di throughput di ogni versione, indicati come numero di rilassamenti al secondo, misurati su ogni scheda.
	\begin{table}[!ht]
		\centering
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Nome versione} & \textbf{940MX} & \textbf{GTX 1070} & \textbf{RTX 2080} \\ \hline
			\texttt{bf0-none-aos-nosh-step}  &  &  &  \\ \hline
			\texttt{bf0-none-aos-sh-step}    &  &  &  \\ \hline
			\texttt{bf0-none-soa-nosh-step}  &  &  &  \\ \hline
			\texttt{bf0-none-soa-sh-step}    &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-nosh-step} &  &  &  \\ \hline
			\texttt{bf0-mutex-aos-sh-step}   &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-nosh-step} &  &  &  \\ \hline
			\texttt{bf0-mutex-soa-sh-step}   &  &  &  \\ \hline
			\texttt{bf0-none-aos-nosh-full}  & N/A &  &  \\ \hline
			\texttt{bf0-none-aos-sh-full}    & N/A &  &  \\ \hline
			\texttt{bf0-none-soa-nosh-full}  & N/A &  &  \\ \hline
			\texttt{bf0-none-soa-sh-full}    & N/A &  &  \\ \hline
			\texttt{bf0-mutex-aos-nosh-full} & N/A &  &  \\ \hline
			\texttt{bf0-mutex-aos-sh-full}   & N/A &  &  \\ \hline
			\texttt{bf0-mutex-soa-nosh-full} & N/A &  &  \\ \hline
			\texttt{bf0-mutex-soa-sh-full}   & N/A &  &  \\ \hline
		\end{tabular}
	\end{table}
	
	
	
	Fonte dei test:
	\begin{itemize}
		\item \url{https://www.moreno.marzolla.name/teaching/LabASD/handouts/bellman-ford.html}
		\item \url{http://users.diag.uniroma1.it/challenge9/download.shtml}
	\end{itemize}
	
	\section{Conclusioni}
	\label{section:end}
	Qui dovrei effettuare un'analisi di tutti i risultati ottenuti e scegliere infine la versione migliore da etichettare come "Bellman-Ford in CUDA".
	
	\printbibliography
	
\end{document}