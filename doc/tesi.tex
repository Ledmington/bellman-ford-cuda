\documentclass{article}

\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}

\title{Implementazione CUDA dell'algoritmo di Bellman-Ford}
\author{Filippo Barbari}
\date{\today}

\begin{document}
	
	\maketitle
	\newpage
	
	\tableofcontents
	\newpage
	
	\listoffigures
	\newpage
	
	\listoftables
	\newpage
	
	\section{Introduzione}
	
	\section{Analisi dell'algoritmo}
	
	\section{Design}
	Varie versioni dell'algoritmo:
	\begin{itemize}
		\item \texttt{bf0}: memorizzare il grafo come array di archi e parallelizzare il ciclo interno ovvero il "per ogni arco del grafo" (usare un thread per ogni arco). In realtà questa versione si ramifica in altre 4 sotto-versioni che variano in base al meccanismo utilizzato per gestire le scritture concorrenti sul vettore \texttt{D}.
		\begin{itemize}
			\item \texttt{bf0-none}: non si utilizza nulla. Gli aggiornamenti dovrebbero essere così poco frequenti che il risultato potrebbe essere comunque corretto. La versione "single-step" produce il risultato corretto sul grafo di Roma, quella non "single-step" produce un risultato di poco diverso (in tutto qualche centinaio di nodi hanno un valore errato).
			\item \texttt{bf0-mutex}: usare una mutex per ogni nodo. Sul grafo di Roma, la versione "single-step" produce il risultato corretto, quella non "single-step" produce un risultato molto diverso.
			\item \texttt{bf0-min}: usare l'istruzione CUDA \texttt{atomicMin}.
			\item \texttt{bf0-cas}: usare l'istruzione CUDA \texttt{atomicCAS}. Come dovrei usarla?
		\end{itemize}
		In alternativa, la versione \texttt{bf0-minred} utilizza una min-reduction per evitare aggiornamenti concorrenti.
	
		\item \texttt{bf1}: memorizzare il grafo come lista di adiacenza (in realtà non serve) e parallelizzare il ciclo interno. Per ogni nodo $u$ si creano tanti thread quanti sono i nodi $v$ a cui è collegato (o semplicemente $N-1$ thread), ognuno di questi thread esegue il relax dell'arco uscente $(u,v)$ aggiornando \texttt{D[v]}. Questa versione usa molti meno thread della \texttt{bf0} ma non ha il problema della concorrenza.
		
		\item \texttt{bf2}: memorizzare il grafo come lista di adiacenza (in realtà non serve) e parallelizzare il ciclo interno. Per ogni nodo $v$ si creano tanti thread quanti sono i nodi $u$ a cui è collegato (o semplicemente $N-1$ thread), ognuno di questi thread esegue il relax dell'arco entrante $(u,v)$ mantenendo un valore parziale, infine si opera una min-reduction per determinare \texttt{D[v]}. Questa versione usa molti meno thread della \texttt{bf0} ma non ha il problema della concorrenza.
	\end{itemize}

	In ogni caso, per ognuna di queste versioni, bisognerebbe provare la versione shared memory e le versione AoS e SoA. Per ottimizzare gli accessi si potrebbe provare a sortare gli archi in base all'esigenza.
	
	\section{Implementazione}
	
	\section{Valutazione delle prestazioni}
	Fonte dei test:
	\begin{itemize}
		\item \url{https://www.moreno.marzolla.name/teaching/LabASD/handouts/bellman-ford.html}
		\item \url{http://users.diag.uniroma1.it/challenge9/download.shtml}
	\end{itemize}
	
	\section{Conclusioni}
	
\end{document}